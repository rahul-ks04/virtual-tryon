{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Agnostic Person Generation\n",
                "\n",
                "This notebook provides a utility to generate \"Agnostic Person\" images and parsing maps. \n",
                "An agnostic person is a representation where the original garment and arms are removed (replaced by a gray area). \n",
                "The gray area is slightly larger than the original garment to break the **Cloth Shape Bias**, ensuring the flow renderer doesn't confine the new garment to the mask of the old one."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import cv2\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# LIP Labels Mapping\n",
                "# Labels to MASK OUT (Gray area):\n",
                "# 5: Upper-clothes, 6: Dress, 7: Coat, 14: Left-arm, 15: Right-arm\n",
                "AGNOSTIC_LABELS = [5, 6, 7, 14, 15]\n",
                "\n",
                "# Labels to PRESERVE (Keep original pixels even if mask overlaps):\n",
                "# 1: Hat, 2: Hair, 4: Sunglasses, 13: Face\n",
                "PRESERVE_LABELS = [1, 2, 4, 13]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Agnostic Generation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_agnostic_person(img_path, parse_path, dilation_kernel_size=25):\n",
                "    \"\"\"\n",
                "    Generates agnostic image and parsing map with feature preservation.\n",
                "    \"\"\"\n",
                "    # Load image and parsing\n",
                "    image = np.array(Image.open(Path(img_path)).convert(\"RGB\"))\n",
                "    parse = np.array(Image.open(Path(parse_path)))\n",
                "\n",
                "    # 1. Create preservation mask (Parts of the person we want to keep at all costs)\n",
                "    preserve_mask = np.isin(parse, PRESERVE_LABELS).astype(np.uint8)\n",
                "\n",
                "    # 2. Create binary mask for agnostic areas (Clothes and Arms)\n",
                "    agnostic_mask = np.isin(parse, AGNOSTIC_LABELS).astype(np.uint8)\n",
                "\n",
                "    # 3. Dilate the agnostic mask to break 'Cloth Shape Bias'\n",
                "    kernel = np.ones((dilation_kernel_size, dilation_kernel_size), np.uint8)\n",
                "    dilated_mask = cv2.dilate(agnostic_mask, kernel, iterations=1)\n",
                "\n",
                "    # 4. Refine Dilated Mask: Subtract the preservation mask\n",
                "    # This ensures gray area doesn't cover hair, face, or hat\n",
                "    final_agnostic_mask = (dilated_mask == 1) & (preserve_mask == 0)\n",
                "\n",
                "    # Create Agnostic Image\n",
                "    agnostic_img = image.copy()\n",
                "    # Replace masked area with neutral gray (128, 128, 128)\n",
                "    agnostic_img[final_agnostic_mask] = [128, 128, 128]\n",
                "    \n",
                "    # Create Agnostic Parsing\n",
                "    # We clear the garment/arm labels from the parsing map\n",
                "    agnostic_parse = parse.copy()\n",
                "    agnostic_parse[agnostic_mask == 1] = 0 # Set to background\n",
                "\n",
                "    return Image.fromarray(agnostic_img), Image.fromarray(agnostic_parse)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Target Guidance Map Generation\n",
                "\n",
                "To achieve true garment independence, we provide a **Guidance Map** to the FEM (Flow Estimation Module).\n",
                "This map has label `5` (Upper-clothes) in a smooth, neutral torso region, so the network estimates flow based on the *pose* rather than the *original garment's silhouette*."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_target_guidance(parse_path, iterations=5):\n",
                "    \"\"\"\n",
                "    Generates a neutral guidance parsing map for the FEM.\n",
                "    \"\"\"\n",
                "    parse = np.array(Image.open(Path(parse_path)))\n",
                "    \n",
                "    # 1. Isolate garment area (Upper-clothes, Dress, Coat)\n",
                "    garment_mask = np.isin(parse, [5, 6, 7]).astype(np.uint8)\n",
                "    \n",
                "    # 2. Smooth/Morph the mask to remove 'bias' (wrinkles, specific edges)\n",
                "    kernel = np.ones((5,5), np.uint8)\n",
                "    # Closing fills small holes and smooths edges\n",
                "    neutral_mask = cv2.morphologyEx(garment_mask, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
                "    # Dilation ensures it fully covers the torso guidance area for the FEM\n",
                "    neutral_mask = cv2.dilate(neutral_mask, kernel, iterations=2)\n",
                "    \n",
                "    # 3. Create a Guidance Parsing Map\n",
                "    # We copy the original but replace the garment area with our 'neutral' one\n",
                "    guidance_parse = parse.copy()\n",
                "    # Set background for the garment area first\n",
                "    guidance_parse[np.isin(parse, [5, 6, 7])] = 0 \n",
                "    # Apply the neutral garment shape as label 5\n",
                "    guidance_parse[neutral_mask == 1] = 5\n",
                "    \n",
                "    return Image.fromarray(guidance_parse)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization / Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "person_id = \"00005_00.jpg\"\n",
                "current_dir = Path.cwd()\n",
                "\n",
                "# Auto-detect project root\n",
                "if (current_dir / \"data\").exists():\n",
                "    project_root = current_dir\n",
                "else:\n",
                "    project_root = current_dir.parent\n",
                "\n",
                "img_path = project_root / \"data\" / \"viton-hd\" / \"train\" / \"image\" / person_id\n",
                "parse_path = project_root / \"data\" / \"viton-hd\" / \"train\" / \"image-parse-v3\" / person_id.replace('.jpg', '.png')\n",
                "\n",
                "if img_path.exists() and parse_path.exists():\n",
                "    agn_img, agn_prse = get_agnostic_person(img_path, parse_path)\n",
                "    guidance_prse = get_target_guidance(parse_path)\n",
                "    \n",
                "    # Visualize results\n",
                "    fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
                "    axes[0].imshow(Image.open(img_path))\n",
                "    axes[0].set_title(\"Original Person\")\n",
                "    axes[0].axis('off')\n",
                "    \n",
                "    axes[1].imshow(agn_img)\n",
                "    axes[1].set_title(\"Agnostic Person (Stage 3 Input)\")\n",
                "    axes[1].axis('off')\n",
                "    \n",
                "    axes[2].imshow(guidance_prse)\n",
                "    axes[2].set_title(\"Guidance Parsing (FEM Stage 2 Input)\")\n",
                "    axes[2].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(f\"Test paths not found. Please check paths: \\n{img_path}\\n{parse_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}